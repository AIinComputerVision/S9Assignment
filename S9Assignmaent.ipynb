{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S9Assignmaent.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP2NqLhx58fo/jVoihbJrwx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIinComputerVision/S9Assignment/blob/master/S9Assignmaent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgAQN6F9C3M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwZ-fhGlC7D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZunJ2pmOC69S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import data_loader\n",
        "\n",
        "import utils\n",
        "from utils import progress_bar\n",
        "import torch\n",
        "'''Train CIFAR10 with PyTorch.'''\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import random_eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPLx0Owk042K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip -q '/content/models.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjSS2Ko0DLtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import resnet\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZBatrUe0JHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e5853c7-4174-431a-e85f-16ae1e9f81c8"
      },
      "source": [
        "#Model\n",
        "\n",
        "print('==> Building model..')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = resnet.ResNet18()\n",
        "net = net.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Building model..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sODm-qpZDLqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bdd108b0-0e29-438e-eadd-85a106440ae7"
      },
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    #transforms.add(random_eraser.get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False)\n",
        "    #),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtRrp7qL5yXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12sLjout5zdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a0586c76-c05f-4f58-9757-cda312cd511f",
        "id": "O189Z36e50Ui",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        }
      },
      "source": [
        "import os\n",
        "# if device == 'cuda':\n",
        "#     net = torch.nn.DataParallel(net)\n",
        "#     cudnn.benchmark = True\n",
        "\n",
        "# if args.resume:\n",
        "#     # Load checkpoint.\n",
        "#     print('==> Resuming from checkpoint..')\n",
        "#     assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "#     checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "#     net.load_state_dict(checkpoint['net'])\n",
        "#     best_acc = checkpoint['acc']\n",
        "#     start_epoch = checkpoint['epoch']\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        #print(('Loss: %.3f | Acc: %.3f%% (%d/%d)') % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                 % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        \n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "            #print(('Loss: %.3f | Acc: %.3f%% (%d/%d)') % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "             \n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 43ms | Tot: 23s606ms | Loss: 0.212 | Acc: 92.620% (46310/50000)\n",
            " [================================================================>]  Step: 21ms | Tot: 2s797ms | Loss: 0.417 | Acc: 87.030% (8703/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 44ms | Tot: 23s549ms | Loss: 0.202 | Acc: 92.906% (46453/50000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s812ms | Loss: 0.407 | Acc: 87.560% (8756/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 44ms | Tot: 23s763ms | Loss: 0.191 | Acc: 93.332% (46666/50000)\n",
            " [================================================================>]  Step: 21ms | Tot: 2s785ms | Loss: 0.419 | Acc: 87.000% (8700/10000)\n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 44ms | Tot: 23s551ms | Loss: 0.184 | Acc: 93.506% (46753/50000)\n",
            " [================================================================>]  Step: 25ms | Tot: 2s779ms | Loss: 0.454 | Acc: 86.570% (8657/10000)\n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 44ms | Tot: 23s601ms | Loss: 0.173 | Acc: 93.870% (46935/50000)\n",
            " [================================================================>]  Step: 20ms | Tot: 2s708ms | Loss: 0.432 | Acc: 87.320% (8732/10000)\n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 44ms | Tot: 23s561ms | Loss: 0.171 | Acc: 94.032% (47016/50000)\n",
            " [================================================================>]  Step: 21ms | Tot: 2s760ms | Loss: 0.467 | Acc: 85.910% (8591/10000)\n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 44ms | Tot: 23s551ms | Loss: 0.166 | Acc: 94.178% (47089/50000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s810ms | Loss: 0.438 | Acc: 87.150% (8715/10000)\n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 43ms | Tot: 23s772ms | Loss: 0.157 | Acc: 94.366% (47183/50000)\n",
            " [================================================================>]  Step: 21ms | Tot: 2s797ms | Loss: 0.417 | Acc: 87.720% (8772/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ed51458b9c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-ed51458b9c98>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pORGfaKjUwuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUQicf9xUyev",
        "colab_type": "text"
      },
      "source": [
        "**with_albumentations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC0Y2ZZM5zRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from albumentations import (\n",
        "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "def strong_aug(p=0.2):  #changed from 0.5 to 0.2\n",
        "    return Compose([\n",
        "       \n",
        "        OneOf([\n",
        "            IAAAdditiveGaussianNoise(),\n",
        "            GaussNoise(),\n",
        "        ], p=0.2),\n",
        "        OneOf([\n",
        "            MotionBlur(p=0.2),\n",
        "            MedianBlur(blur_limit=3, p=0.1),\n",
        "            Blur(blur_limit=3, p=0.1),\n",
        "        ], p=0.2),\n",
        "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=10, p=0.2),\n",
        "        OneOf([\n",
        "            OpticalDistortion(p=0.3),\n",
        "            GridDistortion(p=0.1),\n",
        "            IAAPiecewiseAffine(p=0.3),\n",
        "        ], p=0.2),\n",
        "        OneOf([\n",
        "            CLAHE(clip_limit=2),\n",
        "            IAASharpen(),\n",
        "            IAAEmboss(),\n",
        "            RandomBrightnessContrast(),\n",
        "        ], p=0.3),\n",
        "        HueSaturationValue(p=0.3),\n",
        "    ], p=p)\n",
        "\n",
        "# image = np.ones((300, 300, 3), dtype=np.uint8)\n",
        "# mask = np.ones((300, 300), dtype=np.uint8)\n",
        "# whatever_data = \"my name\"\n",
        "# augmentation = strong_aug(p=0.9)\n",
        "# data = {\"image\": image, \"mask\": mask, \"whatever_data\": whatever_data, \"additional\": \"hello\"}\n",
        "# augmented = augmentation(**data)\n",
        "# image, mask, whatever_data, additional = augmented[\"image\"], augmented[\"mask\"], augmented[\"whatever_data\"], augmented[\"additional\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev5eqSzX5yRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "67a3dacc-a6ab-4ed5-f691-9ee14d34a9b4",
        "id": "t2AQQBquLX9S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('==> Preparing data..')\n",
        "\n",
        "transform_train_albumed = strong_aug()\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_albumed)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efkg5lWg5yFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "419a5cc7-ea3f-4f31-d9e5-2280adfd483f"
      },
      "source": [
        "import os\n",
        "# if device == 'cuda':\n",
        "#     net = torch.nn.DataParallel(net)\n",
        "#     cudnn.benchmark = True\n",
        "\n",
        "# if args.resume:\n",
        "#     # Load checkpoint.\n",
        "#     print('==> Resuming from checkpoint..')\n",
        "#     assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "#     checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "#     net.load_state_dict(checkpoint['net'])\n",
        "#     best_acc = checkpoint['acc']\n",
        "#     start_epoch = checkpoint['epoch']\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        #print(('Loss: %.3f | Acc: %.3f%% (%d/%d)') % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                 % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        \n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "            #print(('Loss: %.3f | Acc: %.3f%% (%d/%d)') % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "             \n",
        "    #Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    #train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [================================================================>]  Step: 19ms | Tot: 2s844ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            "Saving..\n",
            " [================================================================>]  Step: 21ms | Tot: 2s854ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 22ms | Tot: 2s802ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s810ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s893ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 20ms | Tot: 2s813ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s963ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s874ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s835ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 23ms | Tot: 2s890ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 22ms | Tot: 2s800ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 18ms | Tot: 2s851ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n",
            " [================================================================>]  Step: 19ms | Tot: 2s793ms | Loss: 0.431 | Acc: 87.630% (8763/10000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-78986035d1e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m#train(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-78986035d1e3>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIfkEhp8DLlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHNS9LUhDxZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import grad_cam\n",
        "from grad_cam import GradCam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF1UWTDDYTu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from keras.applications import vgg19\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-RlcB-laGGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "78793d82-7ef7-41d0-90c2-dacb3ba638e7"
      },
      "source": [
        "import argparse\n",
        "from torchvision import models\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--use-cuda', action='store_true', default=False,\n",
        "                        help='Use NVIDIA GPU acceleration')\n",
        "    parser.add_argument('--image-path', type=str)\n",
        "args=get_args()\n",
        "grad_cam = GradCam(model=models.vgg19(pretrained=True), \\\n",
        "                       target_layer_names=[\"35\"], use_cuda=args.use_cuda)\n",
        "\n",
        "\n",
        "img = cv2.imread('/content/horse_dog.jpg', 1)\n",
        "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
        "input = preprocess_image(img)\n",
        "\n",
        "    # If None, returns the map for the highest scoring category.\n",
        "    # Otherwise, targets the requested index.\n",
        "target_index = None\n",
        "mask = grad_cam(input, target_index)\n",
        "\n",
        "show_cam_on_image(img, mask)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-e9eb0cd7fc5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--image-path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrad_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradCam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0mtarget_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"35\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'use_cuda'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acNimDarjrt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}